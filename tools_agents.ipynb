{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a52360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arxiv Research\n",
    "# Tools Creation\n",
    "\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b8dae",
   "metadata": {},
   "source": [
    "```markdown\n",
    "1. Wikipedia ve Arxiv AraÃ§larÄ±nÄ±n OluÅŸturulmasÄ±\n",
    "AmaÃ§: Wikipedia ve Arxiv sorgularÄ± iÃ§in gerekli araÃ§ ve yardÄ±mcÄ± sÄ±nÄ±flarÄ± projeye dahil eder.\n",
    "WikipediaQueryRun & ArxivQueryRun: Wikipedia ve Arxiv Ã¼zerinde arama yapabilen araÃ§lar.\n",
    "WikipediaAPIWrapper & ArxivAPIWrapper: Bu araÃ§larÄ±n arka planda kullandÄ±ÄŸÄ± API sarmalayÄ±cÄ±larÄ±.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b9533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used the inbuilt tool of wikipedia\n",
    "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "wiki.name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2085c4fd",
   "metadata": {},
   "source": [
    "```markdown\n",
    "2. Wikipedia AracÄ±nÄ±n OluÅŸturulmasÄ±\n",
    "AmaÃ§: Wikipedia'da arama yapacak bir araÃ§ oluÅŸturmak.\n",
    "WikipediaAPIWrapper: Wikipedia'dan en fazla 1 sonuÃ§ ve 200 karakterlik iÃ§erik Ã§eker.\n",
    "WikipediaQueryRun: Bu sarmalayÄ±cÄ±yÄ± kullanarak Wikipedia sorgularÄ± yapar.\n",
    "wiki.name: AracÄ±n adÄ±nÄ± gÃ¶sterir.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dea2437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "arxiv = ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "print(arxiv.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341c9a19",
   "metadata": {},
   "source": [
    "```markdown\n",
    "3. Arxiv AracÄ±nÄ±n OluÅŸturulmasÄ±\n",
    "AmaÃ§: Arxiv'de arama yapacak bir araÃ§ oluÅŸturmak.\n",
    "ArxivAPIWrapper: Arxiv'den en fazla 1 sonuÃ§ ve 250 karakterlik iÃ§erik Ã§eker.\n",
    "ArxivQueryRun: Bu sarmalayÄ±cÄ±yÄ± kullanarak Arxiv sorgularÄ± yapar.\n",
    "print(arxiv.name): AracÄ±n adÄ±nÄ± ekrana yazdÄ±rÄ±r.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a3eacf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki,arxiv]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f608dca5",
   "metadata": {},
   "source": [
    "```markdown\n",
    "4. AraÃ§larÄ±n Listeye Eklenmesi\n",
    "AmaÃ§: OluÅŸturulan araÃ§larÄ± bir listeye ekleyerek daha sonra topluca kullanmak.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0593f148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# Custom tools (Rag Tool)\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb661061",
   "metadata": {},
   "source": [
    "```markdown\n",
    "5. Kendi DokÃ¼manÄ±nÄ±zdan Arama Yapacak AracÄ±n OluÅŸturulmasÄ± (RAG Tool)\n",
    "AmaÃ§: Belirli bir web sayfasÄ±ndan (Ã¶r: LangSmith dokÃ¼mantasyonu) veri Ã§ekip, bu veriyi vektÃ¶r veritabanÄ±na kaydetmek ve arama yapÄ±labilir hale getirmek.\n",
    "WebBaseLoader: Web sayfasÄ± iÃ§eriÄŸini Ã§eker.\n",
    "RecursiveCharacterTextSplitter: Ä°Ã§eriÄŸi kÃ¼Ã§Ã¼k parÃ§alara bÃ¶ler.\n",
    "OpenAIEmbeddings: ParÃ§alarÄ± vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n",
    "FAISS: VektÃ¶rleri saklayan ve arama yapabilen veritabanÄ±.\n",
    "retriever: Bu veritabanÄ±nda arama yapmayÄ± saÄŸlayan nesne.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5414e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000288F5DD13D0>, search_kwargs={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "vectordb = FAISS.from_documents(documents,OpenAIEmbeddings())\n",
    "retriever = vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d510f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith-search'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(retriever,\"langsmith-search\",\"Search any information about Langsmith\")\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79091230",
   "metadata": {},
   "source": [
    "```markdown\n",
    "6. Retriever Tool'un OluÅŸturulmasÄ±\n",
    "AmaÃ§: YukarÄ±da oluÅŸturulan retriever'Ä± bir araca dÃ¶nÃ¼ÅŸtÃ¼rmek.\n",
    "create_retriever_tool: Retriever'Ä±, agent'Ä±n kullanabileceÄŸi bir araca Ã§evirir.\n",
    "retriever_tool.name: AracÄ±n adÄ±nÄ± gÃ¶sterir\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3673dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c1c0e4",
   "metadata": {},
   "source": [
    "```markdown\n",
    "7. TÃ¼m AraÃ§larÄ±n Listeye Eklenmesi\n",
    "AmaÃ§: ArtÄ±k Ã¼Ã§ farklÄ± kaynaktan (Wikipedia, Arxiv, LangSmith dokÃ¼manÄ±) arama yapabilen araÃ§lar tek bir listede.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08ec10dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all this tools with Agents and LLM Models\n",
    "# Tools, LLM -> AgentExecutor\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "load_dotenv()\n",
    "import os \n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(groq_api_key = groq_api_key,model_name =\"Llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af682fa",
   "metadata": {},
   "source": [
    "```markdown\n",
    "8. LLM ve Ortam DeÄŸiÅŸkenlerinin AyarlanmasÄ±\n",
    "AmaÃ§: BÃ¼yÃ¼k dil modelini (LLM) ve gerekli API anahtarlarÄ±nÄ± ayarlamak.\n",
    "load_dotenv(): .env dosyasÄ±ndan anahtarlarÄ± yÃ¼kler.\n",
    "ChatGroq: Groq firmasÄ±nÄ±n Llama3 modelini kullanÄ±r.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59a64bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt Template\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02110579",
   "metadata": {},
   "source": [
    "```markdown\n",
    "9. Prompt Template'in HazÄ±rlanmasÄ±\n",
    "AmaÃ§: Agent'Ä±n kullanacaÄŸÄ± hazÄ±r prompt ÅŸablonunu almak.\n",
    "hub.pull: LangChain Hub'dan hazÄ±r prompt Ã§eker.\n",
    "\n",
    "\n",
    "hub Nedir?\n",
    "hub, LangChain ekosisteminde, topluluk tarafÄ±ndan hazÄ±rlanmÄ±ÅŸ ve paylaÅŸÄ±lan hazÄ±r prompt ÅŸablonlarÄ±nÄ±, zincirleri (chains), agent yapÄ±larÄ±nÄ± ve diÄŸer bileÅŸenleri merkezi bir depodan kolayca Ã§ekmenizi saÄŸlayan bir modÃ¼ldÃ¼r.\n",
    "Yani, kendi promptunuzu sÄ±fÄ±rdan yazmak yerine, baÅŸkalarÄ±nÄ±n hazÄ±rladÄ±ÄŸÄ± ve test ettiÄŸi ÅŸablonlarÄ± hÄ±zlÄ±ca kullanabilirsiniz.\n",
    "Kodun AÃ§Ä±klamasÄ±\n",
    "hub.pull(\"hwchase17/openai-functions-agent\") fonksiyonu, LangChain Hub'dan \"hwchase17/openai-functions-agent\" isimli hazÄ±r bir agent prompt ÅŸablonunu indirir.\n",
    "Bu ÅŸablon, OpenAI fonksiyonlarÄ±yla Ã§alÄ±ÅŸan bir agent iÃ§in optimize edilmiÅŸtir ve genellikle araÃ§ kullanan (tool-using) agent'lar iÃ§in Ã¶nerilir.\n",
    "SonuÃ§ olarak, prompt deÄŸiÅŸkeni artÄ±k bu hazÄ±r ÅŸablonun iÃ§eriÄŸini tutar ve agent oluÅŸtururken doÄŸrudan kullanÄ±labilir.\n",
    "Neden KullanÄ±lÄ±r?\n",
    "Zaman kazandÄ±rÄ±r: SÄ±fÄ±rdan prompt yazmak yerine, topluluk tarafÄ±ndan denenmiÅŸ bir ÅŸablon kullanÄ±rsÄ±nÄ±z.\n",
    "StandartlaÅŸtÄ±rÄ±r: FarklÄ± projelerde aynÄ± ÅŸablonu tekrar tekrar kullanabilirsiniz.\n",
    "GÃ¼ncel kalÄ±r: Hubâ€™daki ÅŸablonlar topluluk tarafÄ±ndan gÃ¼ncellenebilir.\n",
    "Ã–zet\n",
    "hub ile, LangChain Hubâ€™daki hazÄ±r bileÅŸenleri kolayca projenize dahil edersiniz.\n",
    "Bu satÄ±r, bir agentâ€™Ä±n nasÄ±l davranacaÄŸÄ±nÄ± ve araÃ§larÄ± nasÄ±l kullanacaÄŸÄ±nÄ± belirleyen, test edilmiÅŸ bir prompt ÅŸablonunu indirir ve kullanÄ±ma hazÄ±r hale getirir.\n",
    "KÄ±sacasÄ±:\n",
    "hub = LangChainâ€™in hazÄ±r ÅŸablon ve zincir deposu,\n",
    "pull = oradan istediÄŸin bileÅŸeni Ã§ekmek iÃ§in kullanÄ±lÄ±r.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bdc9bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000288E4FEAFC0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000288E4FEAFC0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000288FA7FB4D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000288FB857B90>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith-search', 'description': 'Search any information about Langsmith', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agents\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm,tools,prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717b37d1",
   "metadata": {},
   "source": [
    "```markdown\n",
    "\n",
    "burada openai agent promptunu kullanÄ±yoruz ama llm llama , bu hazÄ±r ÅŸablonu kullandÄ±ÄŸÄ±mÄ±z iÃ§in create_openai_tools_agent fonksiyonunu kullanmak zorundayÄ±z deÄŸil mi?\n",
    "\n",
    "\n",
    "\n",
    "Evet, doÄŸru anladÄ±nÄ±z.\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\") satÄ±rÄ± ile OpenAI fonksiyon tabanlÄ± bir agent iÃ§in hazÄ±rlanmÄ±ÅŸ bir prompt ÅŸablonu kullanÄ±yorsunuz. Bu ÅŸablon, araÃ§ kullanan (tool-using) agent yapÄ±sÄ± iÃ§in optimize edilmiÅŸtir ve LangChain'de OpenAI uyumlu agent fonksiyonlarÄ±yla Ã§alÄ±ÅŸacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.\n",
    "\n",
    "Bu nedenle, bu prompt ile birlikte agent oluÅŸturmak iÃ§in:\n",
    "\n",
    "fonksiyonunu kullanmak gerekir.\n",
    "\n",
    "Burada LLM olarak Llama (Ã¶r. Groq Ã¼zerinden) kullanmanÄ±zda teknik olarak bir engel yoktur; Ã§Ã¼nkÃ¼ LangChain, OpenAI API uyumlu baÅŸka modelleri de bu fonksiyonla Ã§alÄ±ÅŸtÄ±rabiliyor. Ancak, prompt ve agent yapÄ±sÄ± OpenAI fonksiyon formatÄ±na gÃ¶re hazÄ±rlandÄ±ÄŸÄ± iÃ§in, bu fonksiyonu kullanmak zorundasÄ±nÄ±z.\n",
    "\n",
    "Ã–zet:\n",
    "EÄŸer bu hazÄ±r OpenAI fonksiyon agent promptunu kullanÄ±yorsanÄ±z, create_openai_tools_agent fonksiyonunu kullanmak zorundasÄ±nÄ±z. LLM'iniz OpenAI API uyumlu olduÄŸu sÃ¼rece (Groq Llama gibi) bu yapÄ± Ã§alÄ±ÅŸÄ±r.\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5c8fff",
   "metadata": {},
   "source": [
    "```markdown\n",
    "10. Agent'Ä±n OluÅŸturulmasÄ±\n",
    "AmaÃ§: LLM, araÃ§lar ve prompt ile bir agent (yapay zeka asistanÄ±) oluÅŸturmak.\n",
    "Agent, hangi soruda hangi aracÄ± kullanacaÄŸÄ±nÄ± otomatik belirler.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfbd9df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000288E4FEAFC0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000288E4FEAFC0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000288FA7FB4D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000288FB857B90>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith-search', 'description': 'Search any information about Langsmith', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\dev\\\\Python\\\\.venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)), Tool(name='langsmith-search', description='Search any information about Langsmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000288F5F1D620>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000288F5DD13D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000288F5F1D760>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000288F5DD13D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent Executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executer = AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cdcd23",
   "metadata": {},
   "source": [
    "```markdown\n",
    "11. AgentExecutor ile Agent'Ä±n Ã‡alÄ±ÅŸtÄ±rÄ±lmasÄ±\n",
    "AmaÃ§: Agent'Ä± ve araÃ§larÄ± bir araya getirip, dÄ±ÅŸarÄ±dan gelen sorularÄ± iÅŸleyip cevap dÃ¶nen bir yapÄ± oluÅŸturmak.\n",
    "verbose=True: AdÄ±m adÄ±m iÅŸlemleri gÃ¶sterir.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b227304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith-search` with `{'query': 'Langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mGet started with LangSmith | ğŸ¦œï¸ğŸ› ï¸ LangSmith\n",
      "\n",
      "LangSmith + LangChain OSSLangSmith is framework-agnostic â€”Â it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
      "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
      "Observabilityâ€‹\n",
      "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
      "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmithâ€™s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\n",
      "\n",
      "Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\n",
      "LangSmith is a platform for building production-grade LLM applications.\n",
      "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "ObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic â€” score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.\n",
      "\n",
      "Get started by adding tracing to your application.\n",
      "Create dashboards to view key metrics like RPS, error rates and costs.\n",
      "\n",
      "Evalsâ€‹\n",
      "The quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\n",
      "\n",
      "Get started by creating your first evaluation.\n",
      "Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\n",
      "Analyze results of evaluations in the LangSmith UI and compare results over time.\n",
      "Easily collect human feedback on your data to improve your application.\n",
      "\n",
      "Prompt Engineeringâ€‹\n",
      "While traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\u001b[0m\u001b[32;1m\u001b[1;3mThe Langsmith platform provides a robust set of tools for building, monitoring, and evaluating Large Language Models (LLMs) applications. It offers observability features, prompt engineering, and evaluation capabilities to help developers create high-quality and production-grade LLM applications.\n",
      "\n",
      "Some key features of Langsmith include:\n",
      "\n",
      "1. Observability: Langsmith provides LLM-native observability, allowing developers to gain meaningful insights into their application's performance and debug any issues.\n",
      "2. Evaluation: Langsmith offers a range of evaluation tools and metrics to help developers test and optimize their LLM applications.\n",
      "3. Prompt Engineering: Langsmith provides a set of tools and features to help developers find the perfect prompts for their LLM applications, making it easier to iterate on prompts and collaborate with others.\n",
      "4. Deployment: Langsmith allows developers to deploy their LLM applications on the LangGraph Platform, which provides scalability, security, and reliability.\n",
      "\n",
      "Overall, Langsmith aims to simplify the process of building and deploying LLM applications, making it easier for developers to create high-quality and production-grade AI applications.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Langsmith',\n",
       " 'output': \"The Langsmith platform provides a robust set of tools for building, monitoring, and evaluating Large Language Models (LLMs) applications. It offers observability features, prompt engineering, and evaluation capabilities to help developers create high-quality and production-grade LLM applications.\\n\\nSome key features of Langsmith include:\\n\\n1. Observability: Langsmith provides LLM-native observability, allowing developers to gain meaningful insights into their application's performance and debug any issues.\\n2. Evaluation: Langsmith offers a range of evaluation tools and metrics to help developers test and optimize their LLM applications.\\n3. Prompt Engineering: Langsmith provides a set of tools and features to help developers find the perfect prompts for their LLM applications, making it easier to iterate on prompts and collaborate with others.\\n4. Deployment: Langsmith allows developers to deploy their LLM applications on the LangGraph Platform, which provides scalability, security, and reliability.\\n\\nOverall, Langsmith aims to simplify the process of building and deploying LLM applications, making it easier for developers to create high-quality and production-grade AI applications.\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({\"input\":\"Tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f5ebb",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Agentâ€™lar, LangChain ve benzeri frameworkâ€™lerde, birden fazla aracÄ± (tool) ve bÃ¼yÃ¼k dil modelini (LLM) bir araya getirip, karmaÅŸÄ±k gÃ¶revleri otomatik olarak Ã§Ã¶zebilen akÄ±llÄ± yapay zeka â€œyÃ¼rÃ¼tÃ¼cÃ¼leridirâ€.\n",
    "\n",
    "KÄ±saca Agent nedir?\n",
    "Agent, kendisine verilen doÄŸal dildeki bir soruyu/parÃ§ayÄ± analiz eder.\n",
    "Hangi aracÄ± (Ã¶r. Wikipedia, Arxiv, Ã¶zel dokÃ¼man arama) kullanmasÄ± gerektiÄŸine kendi karar verir.\n",
    "Gerekirse birden fazla aracÄ± art arda veya birlikte kullanabilir.\n",
    "SonuÃ§larÄ± birleÅŸtirip, kullanÄ±cÄ±ya anlamlÄ± bir cevap dÃ¶ndÃ¼rÃ¼r.\n",
    "Ne iÅŸe yarar?\n",
    "Ã‡oklu bilgi kaynaÄŸÄ±: FarklÄ± kaynaklardan (web, vektÃ¶r veritabanÄ±, API, Wikipedia, Arxiv vs.) otomatik bilgi toplar.\n",
    "Otomasyon: Hangi adÄ±mda hangi aracÄ± kullanacaÄŸÄ±nÄ±, hangi sÄ±rayla Ã§alÄ±ÅŸacaÄŸÄ±nÄ± kendi belirler.\n",
    "AkÄ±llÄ± yÃ¶nlendirme: Sadece bir LLMâ€™den cevap almak yerine, gerektiÄŸinde dÄ±ÅŸ veri kaynaklarÄ±na baÅŸvurur.\n",
    "KarmaÅŸÄ±k gÃ¶revler: Sadece soru-cevap deÄŸil, zincirleme iÅŸlemler, veri toplama, Ã¶zetleme gibi gÃ¶revleri de Ã¼stlenebilir.\n",
    "Ã–rnek\n",
    "KullanÄ±cÄ± â€œAtatÃ¼rk kimdir?â€ diye sorduÄŸunda:\n",
    "\n",
    "Agent Ã¶nce Wikipedia aracÄ±nÄ± kullanmaya karar verir, oradan bilgi Ã§eker.\n",
    "â€œLangSmith nedir?â€ sorusunda ise kendi Ã¶zel dokÃ¼man arama aracÄ±nÄ± kullanÄ±r.\n",
    "TÃ¼m bu sÃ¼reci, sizin kod yazmanÄ±za gerek kalmadan, kendi baÅŸÄ±na yÃ¶netir.\n",
    "Ã–zet\n",
    "Agent = AkÄ±llÄ±, Ã§ok kaynaklÄ±, otomatik karar veren yapay zeka yÃ¼rÃ¼tÃ¼cÃ¼sÃ¼\n",
    "KullanÄ±cÄ±dan gelen sorularÄ± analiz eder, uygun aracÄ± seÃ§er, Ã§alÄ±ÅŸtÄ±rÄ±r ve cevabÄ± Ã¼retir.\n",
    "LangChainâ€™de agentâ€™lar, LLM ve araÃ§larÄ± birleÅŸtirerek Ã§ok daha esnek ve gÃ¼Ã§lÃ¼ uygulamalar geliÅŸtirmenizi saÄŸlar.\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d71e31",
   "metadata": {},
   "source": [
    "```markdown\n",
    "12. SorgularÄ±n Agent'a GÃ¶nderilmesi\n",
    "AmaÃ§: KullanÄ±cÄ±dan gelen doÄŸal dildeki sorularÄ± agent'a iletmek ve cevap almak.\n",
    "Agent, sorunun iÃ§eriÄŸine gÃ¶re uygun aracÄ± seÃ§ip, cevabÄ± Ã¼retir.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "287284fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'machine learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'machine learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mIt seems like we've already covered the basics of machine learning. Based on the information provided, it appears that machine learning is a subfield of artificial intelligence that involves developing and studying statistical algorithms that can learn from data and make predictions or decisions.\n",
      "\n",
      "Machine learning is a rapidly growing field with many applications in various industries, including but not limited to natural language processing, computer vision, speech recognition, and predictive analytics.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is machine learning?',\n",
       " 'output': \"It seems like we've already covered the basics of machine learning. Based on the information provided, it appears that machine learning is a subfield of artificial intelligence that involves developing and studying statistical algorithms that can learn from data and make predictions or decisions.\\n\\nMachine learning is a rapidly growing field with many applications in various industries, including but not limited to natural language processing, computer vision, speech recognition, and predictive analytics.\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({\"input\":\"What is machine learning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17cbbdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Mustafa Kemal AtatÃ¼rk'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Mustafa Kemal AtatÃ¼rk\n",
      "Summary: Mustafa Kemal AtatÃ¼rk (c. 1881 â€“ 10 November 1938) was a Turkish field marshal and revolutionary statesman who was the founding father of the Republic of Turkey, s\u001b[0m\u001b[32;1m\u001b[1;3mMustafa Kemal AtatÃ¼rk was a Turkish field marshal and revolutionary statesman who was the founding father of the Republic of Turkey. He played a key role in the Turkish War of Independence and served as the first President of Turkey from 1923 until his death in 1938.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is AtatÃ¼rk?',\n",
       " 'output': 'Mustafa Kemal AtatÃ¼rk was a Turkish field marshal and revolutionary statesman who was the founding father of the Republic of Turkey. He played a key role in the Turkish War of Independence and served as the first President of Turkey from 1923 until his death in 1938.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({\"input\":\"Who is AtatÃ¼rk?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94e88cf",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Ã–zet:\n",
    "Bu kodlar, Wikipedia, Arxiv ve kendi dokÃ¼manÄ±nÄ±zdan arama yapabilen, LLM destekli bir yapay zeka asistanÄ± oluÅŸturur. Her kod parÃ§asÄ±, bu asistanÄ±n bir parÃ§asÄ±nÄ± inÅŸa eder ve sonunda doÄŸal dilde sorulara otomatik olarak doÄŸru kaynaktan cevap verebilen bir sistem elde edilir.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9ead90",
   "metadata": {},
   "source": [
    "```markdown\n",
    "EÄŸer Wikipedia veya Arxiv dÄ±ÅŸÄ±ndaki istediÄŸiniz bir web sitesini dokÃ¼man haline getirip arama yapÄ±labilir bir araca dÃ¶nÃ¼ÅŸtÃ¼rmek isterseniz, aÅŸaÄŸÄ±daki adÄ±mlarÄ± izlemelisiniz:\n",
    "\n",
    "1. Web Sitesinin Ä°Ã§eriÄŸini YÃ¼kleyin\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://istediÄŸiniz-site.com\")\n",
    "docs = loader.load()\n",
    "\n",
    "Burada \"https://istediÄŸiniz-site.com\" kÄ±smÄ±nÄ± kendi istediÄŸiniz web sitesiyle deÄŸiÅŸtirin.\n",
    "docs deÄŸiÅŸkeni, sitenin metin iÃ§eriÄŸini tutar.\n",
    "\n",
    "2. DokÃ¼manlarÄ± ParÃ§alara BÃ¶lÃ¼n\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "\n",
    "BÃ¼yÃ¼k metinleri kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rÄ±r, bÃ¶ylece daha verimli arama yapÄ±labilir.\n",
    "\n",
    "3. Embedding ve VektÃ¶r VeritabanÄ± OluÅŸturun\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectordb = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "Her bir dokÃ¼man parÃ§asÄ± vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r ve FAISS veritabanÄ±nda saklanÄ±r.\n",
    "retriever ile bu veritabanÄ±nda arama yapÄ±labilir.\n",
    "\n",
    "4. Retriever'Ä± Bir Araca DÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"my-custom-site-search\",\n",
    "    \"Search any information from my custom site\"\n",
    ")\n",
    "\n",
    "ArtÄ±k bu araÃ§, agent tarafÄ±ndan kullanÄ±labilir.\n",
    "\n",
    "\n",
    "5. AracÄ± tools listesine ekleyin\n",
    "\n",
    "tools = [wiki, arxiv, retriever_tool]\n",
    "\n",
    "BÃ¶ylece agent, yeni eklediÄŸiniz web sitesinde de arama yapabilir.\n",
    "\n",
    "Ã–zet:\n",
    "Wikipedia ve Arxiv dÄ±ÅŸÄ±ndaki herhangi bir web sitesini de aynÄ± yÃ¶ntemle dokÃ¼man haline getirip, arama yapÄ±labilir bir araca dÃ¶nÃ¼ÅŸtÃ¼rebilirsiniz. Sadece WebBaseLoader'a istediÄŸiniz sitenin adresini verin ve yukarÄ±daki adÄ±mlarÄ± uygulayÄ±n.\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
