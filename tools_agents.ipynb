{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a52360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arxiv Research\n",
    "# Tools Creation\n",
    "\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b8dae",
   "metadata": {},
   "source": [
    "```markdown\n",
    "1. Wikipedia ve Arxiv Araçlarının Oluşturulması\n",
    "Amaç: Wikipedia ve Arxiv sorguları için gerekli araç ve yardımcı sınıfları projeye dahil eder.\n",
    "WikipediaQueryRun & ArxivQueryRun: Wikipedia ve Arxiv üzerinde arama yapabilen araçlar.\n",
    "WikipediaAPIWrapper & ArxivAPIWrapper: Bu araçların arka planda kullandığı API sarmalayıcıları.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b9533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used the inbuilt tool of wikipedia\n",
    "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "wiki.name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2085c4fd",
   "metadata": {},
   "source": [
    "```markdown\n",
    "2. Wikipedia Aracının Oluşturulması\n",
    "Amaç: Wikipedia'da arama yapacak bir araç oluşturmak.\n",
    "WikipediaAPIWrapper: Wikipedia'dan en fazla 1 sonuç ve 200 karakterlik içerik çeker.\n",
    "WikipediaQueryRun: Bu sarmalayıcıyı kullanarak Wikipedia sorguları yapar.\n",
    "wiki.name: Aracın adını gösterir.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dea2437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "arxiv = ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "print(arxiv.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341c9a19",
   "metadata": {},
   "source": [
    "```markdown\n",
    "3. Arxiv Aracının Oluşturulması\n",
    "Amaç: Arxiv'de arama yapacak bir araç oluşturmak.\n",
    "ArxivAPIWrapper: Arxiv'den en fazla 1 sonuç ve 250 karakterlik içerik çeker.\n",
    "ArxivQueryRun: Bu sarmalayıcıyı kullanarak Arxiv sorguları yapar.\n",
    "print(arxiv.name): Aracın adını ekrana yazdırır.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a3eacf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki,arxiv]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f608dca5",
   "metadata": {},
   "source": [
    "```markdown\n",
    "4. Araçların Listeye Eklenmesi\n",
    "Amaç: Oluşturulan araçları bir listeye ekleyerek daha sonra topluca kullanmak.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0593f148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# Custom tools (Rag Tool)\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb661061",
   "metadata": {},
   "source": [
    "```markdown\n",
    "5. Kendi Dokümanınızdan Arama Yapacak Aracın Oluşturulması (RAG Tool)\n",
    "Amaç: Belirli bir web sayfasından (ör: LangSmith dokümantasyonu) veri çekip, bu veriyi vektör veritabanına kaydetmek ve arama yapılabilir hale getirmek.\n",
    "WebBaseLoader: Web sayfası içeriğini çeker.\n",
    "RecursiveCharacterTextSplitter: İçeriği küçük parçalara böler.\n",
    "OpenAIEmbeddings: Parçaları vektörlere dönüştürür.\n",
    "FAISS: Vektörleri saklayan ve arama yapabilen veritabanı.\n",
    "retriever: Bu veritabanında arama yapmayı sağlayan nesne.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5414e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000288F5DD13D0>, search_kwargs={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "vectordb = FAISS.from_documents(documents,OpenAIEmbeddings())\n",
    "retriever = vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d510f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith-search'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(retriever,\"langsmith-search\",\"Search any information about Langsmith\")\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79091230",
   "metadata": {},
   "source": [
    "```markdown\n",
    "6. Retriever Tool'un Oluşturulması\n",
    "Amaç: Yukarıda oluşturulan retriever'ı bir araca dönüştürmek.\n",
    "create_retriever_tool: Retriever'ı, agent'ın kullanabileceği bir araca çevirir.\n",
    "retriever_tool.name: Aracın adını gösterir\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3673dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c1c0e4",
   "metadata": {},
   "source": [
    "```markdown\n",
    "7. Tüm Araçların Listeye Eklenmesi\n",
    "Amaç: Artık üç farklı kaynaktan (Wikipedia, Arxiv, LangSmith dokümanı) arama yapabilen araçlar tek bir listede.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08ec10dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all this tools with Agents and LLM Models\n",
    "# Tools, LLM -> AgentExecutor\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "load_dotenv()\n",
    "import os \n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(groq_api_key = groq_api_key,model_name =\"Llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af682fa",
   "metadata": {},
   "source": [
    "```markdown\n",
    "8. LLM ve Ortam Değişkenlerinin Ayarlanması\n",
    "Amaç: Büyük dil modelini (LLM) ve gerekli API anahtarlarını ayarlamak.\n",
    "load_dotenv(): .env dosyasından anahtarları yükler.\n",
    "ChatGroq: Groq firmasının Llama3 modelini kullanır.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59a64bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt Template\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02110579",
   "metadata": {},
   "source": [
    "```markdown\n",
    "9. Prompt Template'in Hazırlanması\n",
    "Amaç: Agent'ın kullanacağı hazır prompt şablonunu almak.\n",
    "hub.pull: LangChain Hub'dan hazır prompt çeker.\n",
    "\n",
    "\n",
    "hub Nedir?\n",
    "hub, LangChain ekosisteminde, topluluk tarafından hazırlanmış ve paylaşılan hazır prompt şablonlarını, zincirleri (chains), agent yapılarını ve diğer bileşenleri merkezi bir depodan kolayca çekmenizi sağlayan bir modüldür.\n",
    "Yani, kendi promptunuzu sıfırdan yazmak yerine, başkalarının hazırladığı ve test ettiği şablonları hızlıca kullanabilirsiniz.\n",
    "Kodun Açıklaması\n",
    "hub.pull(\"hwchase17/openai-functions-agent\") fonksiyonu, LangChain Hub'dan \"hwchase17/openai-functions-agent\" isimli hazır bir agent prompt şablonunu indirir.\n",
    "Bu şablon, OpenAI fonksiyonlarıyla çalışan bir agent için optimize edilmiştir ve genellikle araç kullanan (tool-using) agent'lar için önerilir.\n",
    "Sonuç olarak, prompt değişkeni artık bu hazır şablonun içeriğini tutar ve agent oluştururken doğrudan kullanılabilir.\n",
    "Neden Kullanılır?\n",
    "Zaman kazandırır: Sıfırdan prompt yazmak yerine, topluluk tarafından denenmiş bir şablon kullanırsınız.\n",
    "Standartlaştırır: Farklı projelerde aynı şablonu tekrar tekrar kullanabilirsiniz.\n",
    "Güncel kalır: Hub’daki şablonlar topluluk tarafından güncellenebilir.\n",
    "Özet\n",
    "hub ile, LangChain Hub’daki hazır bileşenleri kolayca projenize dahil edersiniz.\n",
    "Bu satır, bir agent’ın nasıl davranacağını ve araçları nasıl kullanacağını belirleyen, test edilmiş bir prompt şablonunu indirir ve kullanıma hazır hale getirir.\n",
    "Kısacası:\n",
    "hub = LangChain’in hazır şablon ve zincir deposu,\n",
    "pull = oradan istediğin bileşeni çekmek için kullanılır.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bdc9bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000288E4FEAFC0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000288E4FEAFC0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000288FA7FB4D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000288FB857B90>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith-search', 'description': 'Search any information about Langsmith', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agents\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm,tools,prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717b37d1",
   "metadata": {},
   "source": [
    "```markdown\n",
    "\n",
    "burada openai agent promptunu kullanıyoruz ama llm llama , bu hazır şablonu kullandığımız için create_openai_tools_agent fonksiyonunu kullanmak zorundayız değil mi?\n",
    "\n",
    "\n",
    "\n",
    "Evet, doğru anladınız.\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\") satırı ile OpenAI fonksiyon tabanlı bir agent için hazırlanmış bir prompt şablonu kullanıyorsunuz. Bu şablon, araç kullanan (tool-using) agent yapısı için optimize edilmiştir ve LangChain'de OpenAI uyumlu agent fonksiyonlarıyla çalışacak şekilde tasarlanmıştır.\n",
    "\n",
    "Bu nedenle, bu prompt ile birlikte agent oluşturmak için:\n",
    "\n",
    "fonksiyonunu kullanmak gerekir.\n",
    "\n",
    "Burada LLM olarak Llama (ör. Groq üzerinden) kullanmanızda teknik olarak bir engel yoktur; çünkü LangChain, OpenAI API uyumlu başka modelleri de bu fonksiyonla çalıştırabiliyor. Ancak, prompt ve agent yapısı OpenAI fonksiyon formatına göre hazırlandığı için, bu fonksiyonu kullanmak zorundasınız.\n",
    "\n",
    "Özet:\n",
    "Eğer bu hazır OpenAI fonksiyon agent promptunu kullanıyorsanız, create_openai_tools_agent fonksiyonunu kullanmak zorundasınız. LLM'iniz OpenAI API uyumlu olduğu sürece (Groq Llama gibi) bu yapı çalışır.\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5c8fff",
   "metadata": {},
   "source": [
    "```markdown\n",
    "10. Agent'ın Oluşturulması\n",
    "Amaç: LLM, araçlar ve prompt ile bir agent (yapay zeka asistanı) oluşturmak.\n",
    "Agent, hangi soruda hangi aracı kullanacağını otomatik belirler.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfbd9df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000288E4FEAFC0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000288E4FEAFC0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000288FA7FB4D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000288FB857B90>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith-search', 'description': 'Search any information about Langsmith', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\dev\\\\Python\\\\.venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)), Tool(name='langsmith-search', description='Search any information about Langsmith', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000288F5F1D620>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000288F5DD13D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000288F5F1D760>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000288F5DD13D0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent Executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executer = AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cdcd23",
   "metadata": {},
   "source": [
    "```markdown\n",
    "11. AgentExecutor ile Agent'ın Çalıştırılması\n",
    "Amaç: Agent'ı ve araçları bir araya getirip, dışarıdan gelen soruları işleyip cevap dönen bir yapı oluşturmak.\n",
    "verbose=True: Adım adım işlemleri gösterir.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b227304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith-search` with `{'query': 'Langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mGet started with LangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
      "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
      "Observability​\n",
      "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
      "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith’s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\n",
      "\n",
      "Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referenceGet StartedOn this pageGet started with LangSmith\n",
      "LangSmith is a platform for building production-grade LLM applications.\n",
      "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "ObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic — score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.\n",
      "\n",
      "Get started by adding tracing to your application.\n",
      "Create dashboards to view key metrics like RPS, error rates and costs.\n",
      "\n",
      "Evals​\n",
      "The quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\n",
      "\n",
      "Get started by creating your first evaluation.\n",
      "Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\n",
      "Analyze results of evaluations in the LangSmith UI and compare results over time.\n",
      "Easily collect human feedback on your data to improve your application.\n",
      "\n",
      "Prompt Engineering​\n",
      "While traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\u001b[0m\u001b[32;1m\u001b[1;3mThe Langsmith platform provides a robust set of tools for building, monitoring, and evaluating Large Language Models (LLMs) applications. It offers observability features, prompt engineering, and evaluation capabilities to help developers create high-quality and production-grade LLM applications.\n",
      "\n",
      "Some key features of Langsmith include:\n",
      "\n",
      "1. Observability: Langsmith provides LLM-native observability, allowing developers to gain meaningful insights into their application's performance and debug any issues.\n",
      "2. Evaluation: Langsmith offers a range of evaluation tools and metrics to help developers test and optimize their LLM applications.\n",
      "3. Prompt Engineering: Langsmith provides a set of tools and features to help developers find the perfect prompts for their LLM applications, making it easier to iterate on prompts and collaborate with others.\n",
      "4. Deployment: Langsmith allows developers to deploy their LLM applications on the LangGraph Platform, which provides scalability, security, and reliability.\n",
      "\n",
      "Overall, Langsmith aims to simplify the process of building and deploying LLM applications, making it easier for developers to create high-quality and production-grade AI applications.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Langsmith',\n",
       " 'output': \"The Langsmith platform provides a robust set of tools for building, monitoring, and evaluating Large Language Models (LLMs) applications. It offers observability features, prompt engineering, and evaluation capabilities to help developers create high-quality and production-grade LLM applications.\\n\\nSome key features of Langsmith include:\\n\\n1. Observability: Langsmith provides LLM-native observability, allowing developers to gain meaningful insights into their application's performance and debug any issues.\\n2. Evaluation: Langsmith offers a range of evaluation tools and metrics to help developers test and optimize their LLM applications.\\n3. Prompt Engineering: Langsmith provides a set of tools and features to help developers find the perfect prompts for their LLM applications, making it easier to iterate on prompts and collaborate with others.\\n4. Deployment: Langsmith allows developers to deploy their LLM applications on the LangGraph Platform, which provides scalability, security, and reliability.\\n\\nOverall, Langsmith aims to simplify the process of building and deploying LLM applications, making it easier for developers to create high-quality and production-grade AI applications.\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({\"input\":\"Tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f5ebb",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Agent’lar, LangChain ve benzeri framework’lerde, birden fazla aracı (tool) ve büyük dil modelini (LLM) bir araya getirip, karmaşık görevleri otomatik olarak çözebilen akıllı yapay zeka “yürütücüleridir”.\n",
    "\n",
    "Kısaca Agent nedir?\n",
    "Agent, kendisine verilen doğal dildeki bir soruyu/parçayı analiz eder.\n",
    "Hangi aracı (ör. Wikipedia, Arxiv, özel doküman arama) kullanması gerektiğine kendi karar verir.\n",
    "Gerekirse birden fazla aracı art arda veya birlikte kullanabilir.\n",
    "Sonuçları birleştirip, kullanıcıya anlamlı bir cevap döndürür.\n",
    "Ne işe yarar?\n",
    "Çoklu bilgi kaynağı: Farklı kaynaklardan (web, vektör veritabanı, API, Wikipedia, Arxiv vs.) otomatik bilgi toplar.\n",
    "Otomasyon: Hangi adımda hangi aracı kullanacağını, hangi sırayla çalışacağını kendi belirler.\n",
    "Akıllı yönlendirme: Sadece bir LLM’den cevap almak yerine, gerektiğinde dış veri kaynaklarına başvurur.\n",
    "Karmaşık görevler: Sadece soru-cevap değil, zincirleme işlemler, veri toplama, özetleme gibi görevleri de üstlenebilir.\n",
    "Örnek\n",
    "Kullanıcı “Atatürk kimdir?” diye sorduğunda:\n",
    "\n",
    "Agent önce Wikipedia aracını kullanmaya karar verir, oradan bilgi çeker.\n",
    "“LangSmith nedir?” sorusunda ise kendi özel doküman arama aracını kullanır.\n",
    "Tüm bu süreci, sizin kod yazmanıza gerek kalmadan, kendi başına yönetir.\n",
    "Özet\n",
    "Agent = Akıllı, çok kaynaklı, otomatik karar veren yapay zeka yürütücüsü\n",
    "Kullanıcıdan gelen soruları analiz eder, uygun aracı seçer, çalıştırır ve cevabı üretir.\n",
    "LangChain’de agent’lar, LLM ve araçları birleştirerek çok daha esnek ve güçlü uygulamalar geliştirmenizi sağlar.\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d71e31",
   "metadata": {},
   "source": [
    "```markdown\n",
    "12. Sorguların Agent'a Gönderilmesi\n",
    "Amaç: Kullanıcıdan gelen doğal dildeki soruları agent'a iletmek ve cevap almak.\n",
    "Agent, sorunun içeriğine göre uygun aracı seçip, cevabı üretir.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "287284fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'machine learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'machine learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mIt seems like we've already covered the basics of machine learning. Based on the information provided, it appears that machine learning is a subfield of artificial intelligence that involves developing and studying statistical algorithms that can learn from data and make predictions or decisions.\n",
      "\n",
      "Machine learning is a rapidly growing field with many applications in various industries, including but not limited to natural language processing, computer vision, speech recognition, and predictive analytics.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is machine learning?',\n",
       " 'output': \"It seems like we've already covered the basics of machine learning. Based on the information provided, it appears that machine learning is a subfield of artificial intelligence that involves developing and studying statistical algorithms that can learn from data and make predictions or decisions.\\n\\nMachine learning is a rapidly growing field with many applications in various industries, including but not limited to natural language processing, computer vision, speech recognition, and predictive analytics.\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({\"input\":\"What is machine learning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17cbbdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Mustafa Kemal Atatürk'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Mustafa Kemal Atatürk\n",
      "Summary: Mustafa Kemal Atatürk (c. 1881 – 10 November 1938) was a Turkish field marshal and revolutionary statesman who was the founding father of the Republic of Turkey, s\u001b[0m\u001b[32;1m\u001b[1;3mMustafa Kemal Atatürk was a Turkish field marshal and revolutionary statesman who was the founding father of the Republic of Turkey. He played a key role in the Turkish War of Independence and served as the first President of Turkey from 1923 until his death in 1938.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is Atatürk?',\n",
       " 'output': 'Mustafa Kemal Atatürk was a Turkish field marshal and revolutionary statesman who was the founding father of the Republic of Turkey. He played a key role in the Turkish War of Independence and served as the first President of Turkey from 1923 until his death in 1938.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({\"input\":\"Who is Atatürk?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94e88cf",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Özet:\n",
    "Bu kodlar, Wikipedia, Arxiv ve kendi dokümanınızdan arama yapabilen, LLM destekli bir yapay zeka asistanı oluşturur. Her kod parçası, bu asistanın bir parçasını inşa eder ve sonunda doğal dilde sorulara otomatik olarak doğru kaynaktan cevap verebilen bir sistem elde edilir.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9ead90",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Eğer Wikipedia veya Arxiv dışındaki istediğiniz bir web sitesini doküman haline getirip arama yapılabilir bir araca dönüştürmek isterseniz, aşağıdaki adımları izlemelisiniz:\n",
    "\n",
    "1. Web Sitesinin İçeriğini Yükleyin\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://istediğiniz-site.com\")\n",
    "docs = loader.load()\n",
    "\n",
    "Burada \"https://istediğiniz-site.com\" kısmını kendi istediğiniz web sitesiyle değiştirin.\n",
    "docs değişkeni, sitenin metin içeriğini tutar.\n",
    "\n",
    "2. Dokümanları Parçalara Bölün\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "\n",
    "Büyük metinleri küçük parçalara ayırır, böylece daha verimli arama yapılabilir.\n",
    "\n",
    "3. Embedding ve Vektör Veritabanı Oluşturun\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectordb = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "Her bir doküman parçası vektörlere dönüştürülür ve FAISS veritabanında saklanır.\n",
    "retriever ile bu veritabanında arama yapılabilir.\n",
    "\n",
    "4. Retriever'ı Bir Araca Dönüştürün\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"my-custom-site-search\",\n",
    "    \"Search any information from my custom site\"\n",
    ")\n",
    "\n",
    "Artık bu araç, agent tarafından kullanılabilir.\n",
    "\n",
    "\n",
    "5. Aracı tools listesine ekleyin\n",
    "\n",
    "tools = [wiki, arxiv, retriever_tool]\n",
    "\n",
    "Böylece agent, yeni eklediğiniz web sitesinde de arama yapabilir.\n",
    "\n",
    "Özet:\n",
    "Wikipedia ve Arxiv dışındaki herhangi bir web sitesini de aynı yöntemle doküman haline getirip, arama yapılabilir bir araca dönüştürebilirsiniz. Sadece WebBaseLoader'a istediğiniz sitenin adresini verin ve yukarıdaki adımları uygulayın.\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
